{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":10771267,"sourceType":"datasetVersion","datasetId":6682176}],"dockerImageVersionId":30886,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"#Loading the necessary packages!\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport optuna\nimport xgboost as xgb\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport scipy.stats as stats\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import GroupKFold\nfrom sklearn.metrics import accuracy_score, classification_report, mean_absolute_error\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.svm import LinearSVC\nfrom sklearn.preprocessing import RobustScaler\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.decomposition import PCA\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.metrics import make_scorer, accuracy_score, median_absolute_error\nfrom imblearn.over_sampling import RandomOverSampler\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.metrics import mean_squared_error, r2_score\nimport lightgbm as lgb\nimport numpy as np\nfrom sklearn.model_selection import KFold\nfrom scipy import stats\nfrom sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, StackingRegressor\nfrom sklearn.linear_model import Ridge\nfrom sklearn.svm import SVR\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import mean_absolute_error\nimport catboost as cb\nfrom scipy.optimize import minimize","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-02-22T17:53:53.941808Z","iopub.execute_input":"2025-02-22T17:53:53.942616Z","iopub.status.idle":"2025-02-22T17:54:01.380028Z","shell.execute_reply.started":"2025-02-22T17:53:53.942573Z","shell.execute_reply":"2025-02-22T17:54:01.378993Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"#Loasding the data!!\ntrain = pd.read_csv(\"/kaggle/input/bagpack11/train.csv\")\ntest = pd.read_csv(\"/kaggle/input/bagpack11/test.csv\")\nextra_train = pd.read_csv(\"/kaggle/input/bagpack11/training_extra.csv\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-22T17:54:01.381330Z","iopub.execute_input":"2025-02-22T17:54:01.381945Z","iopub.status.idle":"2025-02-22T17:54:11.886266Z","shell.execute_reply.started":"2025-02-22T17:54:01.381917Z","shell.execute_reply":"2025-02-22T17:54:11.885226Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"train.head(10)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-22T17:54:11.888031Z","iopub.execute_input":"2025-02-22T17:54:11.888424Z","iopub.status.idle":"2025-02-22T17:54:11.922354Z","shell.execute_reply.started":"2025-02-22T17:54:11.888397Z","shell.execute_reply":"2025-02-22T17:54:11.921229Z"}},"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"   id         Brand   Material    Size  Compartments Laptop Compartment  \\\n0   0      Jansport    Leather  Medium           7.0                Yes   \n1   1      Jansport     Canvas   Small          10.0                Yes   \n2   2  Under Armour    Leather   Small           2.0                Yes   \n3   3          Nike      Nylon   Small           8.0                Yes   \n4   4        Adidas     Canvas  Medium           1.0                Yes   \n5   5          Nike     Canvas  Medium          10.0                 No   \n6   6          Nike        NaN   Large           3.0                 No   \n7   7          Puma     Canvas   Small           1.0                Yes   \n8   8  Under Armour  Polyester  Medium           8.0                Yes   \n9   9  Under Armour      Nylon  Medium           2.0                Yes   \n\n  Waterproof      Style  Color  Weight Capacity (kg)      Price  \n0         No       Tote  Black             11.611723  112.15875  \n1        Yes  Messenger  Green             27.078537   68.88056  \n2         No  Messenger    Red             16.643760   39.17320  \n3         No  Messenger  Green             12.937220   80.60793  \n4        Yes  Messenger  Green             17.749338   86.02312  \n5        Yes        NaN  Black              7.241812   20.01553  \n6         No   Backpack  Green              6.828123   84.80500  \n7        Yes   Backpack   Blue             21.488864   27.15815  \n8         No       Tote   Gray             10.207780   25.98652  \n9        Yes  Messenger   Pink             15.895100   38.48741  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>Brand</th>\n      <th>Material</th>\n      <th>Size</th>\n      <th>Compartments</th>\n      <th>Laptop Compartment</th>\n      <th>Waterproof</th>\n      <th>Style</th>\n      <th>Color</th>\n      <th>Weight Capacity (kg)</th>\n      <th>Price</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>Jansport</td>\n      <td>Leather</td>\n      <td>Medium</td>\n      <td>7.0</td>\n      <td>Yes</td>\n      <td>No</td>\n      <td>Tote</td>\n      <td>Black</td>\n      <td>11.611723</td>\n      <td>112.15875</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>Jansport</td>\n      <td>Canvas</td>\n      <td>Small</td>\n      <td>10.0</td>\n      <td>Yes</td>\n      <td>Yes</td>\n      <td>Messenger</td>\n      <td>Green</td>\n      <td>27.078537</td>\n      <td>68.88056</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>Under Armour</td>\n      <td>Leather</td>\n      <td>Small</td>\n      <td>2.0</td>\n      <td>Yes</td>\n      <td>No</td>\n      <td>Messenger</td>\n      <td>Red</td>\n      <td>16.643760</td>\n      <td>39.17320</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>Nike</td>\n      <td>Nylon</td>\n      <td>Small</td>\n      <td>8.0</td>\n      <td>Yes</td>\n      <td>No</td>\n      <td>Messenger</td>\n      <td>Green</td>\n      <td>12.937220</td>\n      <td>80.60793</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>Adidas</td>\n      <td>Canvas</td>\n      <td>Medium</td>\n      <td>1.0</td>\n      <td>Yes</td>\n      <td>Yes</td>\n      <td>Messenger</td>\n      <td>Green</td>\n      <td>17.749338</td>\n      <td>86.02312</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>5</td>\n      <td>Nike</td>\n      <td>Canvas</td>\n      <td>Medium</td>\n      <td>10.0</td>\n      <td>No</td>\n      <td>Yes</td>\n      <td>NaN</td>\n      <td>Black</td>\n      <td>7.241812</td>\n      <td>20.01553</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>6</td>\n      <td>Nike</td>\n      <td>NaN</td>\n      <td>Large</td>\n      <td>3.0</td>\n      <td>No</td>\n      <td>No</td>\n      <td>Backpack</td>\n      <td>Green</td>\n      <td>6.828123</td>\n      <td>84.80500</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>7</td>\n      <td>Puma</td>\n      <td>Canvas</td>\n      <td>Small</td>\n      <td>1.0</td>\n      <td>Yes</td>\n      <td>Yes</td>\n      <td>Backpack</td>\n      <td>Blue</td>\n      <td>21.488864</td>\n      <td>27.15815</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>8</td>\n      <td>Under Armour</td>\n      <td>Polyester</td>\n      <td>Medium</td>\n      <td>8.0</td>\n      <td>Yes</td>\n      <td>No</td>\n      <td>Tote</td>\n      <td>Gray</td>\n      <td>10.207780</td>\n      <td>25.98652</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>9</td>\n      <td>Under Armour</td>\n      <td>Nylon</td>\n      <td>Medium</td>\n      <td>2.0</td>\n      <td>Yes</td>\n      <td>Yes</td>\n      <td>Messenger</td>\n      <td>Pink</td>\n      <td>15.895100</td>\n      <td>38.48741</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":3},{"cell_type":"code","source":"test.head(10)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-22T17:54:11.923966Z","iopub.execute_input":"2025-02-22T17:54:11.924372Z","iopub.status.idle":"2025-02-22T17:54:11.939262Z","shell.execute_reply.started":"2025-02-22T17:54:11.924337Z","shell.execute_reply":"2025-02-22T17:54:11.938289Z"}},"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"       id         Brand   Material    Size  Compartments Laptop Compartment  \\\n0  300000          Puma    Leather   Small           2.0                 No   \n1  300001          Nike     Canvas  Medium           7.0                 No   \n2  300002        Adidas     Canvas   Large           9.0                 No   \n3  300003        Adidas      Nylon   Large           1.0                Yes   \n4  300004           NaN      Nylon   Large           2.0                Yes   \n5  300005  Under Armour      Nylon  Medium           8.0                 No   \n6  300006          Nike      Nylon   Large           8.0                 No   \n7  300007      Jansport  Polyester  Medium           6.0                Yes   \n8  300008          Nike     Canvas   Large           8.0                Yes   \n9  300009          Puma    Leather   Large           1.0                 No   \n\n  Waterproof      Style  Color  Weight Capacity (kg)  \n0         No       Tote  Green             20.671147  \n1        Yes   Backpack  Green             13.564105  \n2        Yes  Messenger   Blue             11.809799  \n3         No  Messenger  Green             18.477036  \n4        Yes       Tote  Black              9.907953  \n5         No   Backpack  Black             17.547673  \n6        Yes       Tote   Blue             16.003025  \n7         No   Backpack   Blue             24.238091  \n8        Yes   Backpack    Red             19.181167  \n9         No       Tote   Blue              9.937962  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>Brand</th>\n      <th>Material</th>\n      <th>Size</th>\n      <th>Compartments</th>\n      <th>Laptop Compartment</th>\n      <th>Waterproof</th>\n      <th>Style</th>\n      <th>Color</th>\n      <th>Weight Capacity (kg)</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>300000</td>\n      <td>Puma</td>\n      <td>Leather</td>\n      <td>Small</td>\n      <td>2.0</td>\n      <td>No</td>\n      <td>No</td>\n      <td>Tote</td>\n      <td>Green</td>\n      <td>20.671147</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>300001</td>\n      <td>Nike</td>\n      <td>Canvas</td>\n      <td>Medium</td>\n      <td>7.0</td>\n      <td>No</td>\n      <td>Yes</td>\n      <td>Backpack</td>\n      <td>Green</td>\n      <td>13.564105</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>300002</td>\n      <td>Adidas</td>\n      <td>Canvas</td>\n      <td>Large</td>\n      <td>9.0</td>\n      <td>No</td>\n      <td>Yes</td>\n      <td>Messenger</td>\n      <td>Blue</td>\n      <td>11.809799</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>300003</td>\n      <td>Adidas</td>\n      <td>Nylon</td>\n      <td>Large</td>\n      <td>1.0</td>\n      <td>Yes</td>\n      <td>No</td>\n      <td>Messenger</td>\n      <td>Green</td>\n      <td>18.477036</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>300004</td>\n      <td>NaN</td>\n      <td>Nylon</td>\n      <td>Large</td>\n      <td>2.0</td>\n      <td>Yes</td>\n      <td>Yes</td>\n      <td>Tote</td>\n      <td>Black</td>\n      <td>9.907953</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>300005</td>\n      <td>Under Armour</td>\n      <td>Nylon</td>\n      <td>Medium</td>\n      <td>8.0</td>\n      <td>No</td>\n      <td>No</td>\n      <td>Backpack</td>\n      <td>Black</td>\n      <td>17.547673</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>300006</td>\n      <td>Nike</td>\n      <td>Nylon</td>\n      <td>Large</td>\n      <td>8.0</td>\n      <td>No</td>\n      <td>Yes</td>\n      <td>Tote</td>\n      <td>Blue</td>\n      <td>16.003025</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>300007</td>\n      <td>Jansport</td>\n      <td>Polyester</td>\n      <td>Medium</td>\n      <td>6.0</td>\n      <td>Yes</td>\n      <td>No</td>\n      <td>Backpack</td>\n      <td>Blue</td>\n      <td>24.238091</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>300008</td>\n      <td>Nike</td>\n      <td>Canvas</td>\n      <td>Large</td>\n      <td>8.0</td>\n      <td>Yes</td>\n      <td>Yes</td>\n      <td>Backpack</td>\n      <td>Red</td>\n      <td>19.181167</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>300009</td>\n      <td>Puma</td>\n      <td>Leather</td>\n      <td>Large</td>\n      <td>1.0</td>\n      <td>No</td>\n      <td>No</td>\n      <td>Tote</td>\n      <td>Blue</td>\n      <td>9.937962</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":4},{"cell_type":"code","source":"extra_train.head(10)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-22T17:54:11.940406Z","iopub.execute_input":"2025-02-22T17:54:11.940945Z","iopub.status.idle":"2025-02-22T17:54:11.966802Z","shell.execute_reply.started":"2025-02-22T17:54:11.940759Z","shell.execute_reply":"2025-02-22T17:54:11.965711Z"}},"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"       id         Brand   Material    Size  Compartments Laptop Compartment  \\\n0  500000  Under Armour     Canvas   Small          10.0                Yes   \n1  500001          Puma  Polyester   Small           4.0                 No   \n2  500002      Jansport  Polyester   Small           8.0                Yes   \n3  500003          Nike      Nylon   Large           7.0                 No   \n4  500004          Nike    Leather   Large           9.0                 No   \n5  500005        Adidas  Polyester  Medium           5.0                 No   \n6  500006      Jansport      Nylon   Large           5.0                Yes   \n7  500007        Adidas  Polyester   Small           9.0                Yes   \n8  500008        Adidas    Leather   Small           6.0                Yes   \n9  500009          Puma      Nylon  Medium           2.0                 No   \n\n  Waterproof      Style  Color  Weight Capacity (kg)      Price  \n0        Yes       Tote   Blue             23.882052  114.11068  \n1        Yes   Backpack  Green             11.869095  129.74972  \n2        Yes       Tote    Red              8.092302   21.37370  \n3         No  Messenger   Pink              7.719581   48.09209  \n4        Yes       Tote  Green             22.741826   77.32461  \n5         No       Tote    NaN             18.834692   35.99599  \n6        Yes  Messenger   Blue             26.882904   40.81006  \n7         No       Tote   Gray             21.716360   71.12733  \n8        Yes       Tote  Green             21.849587   76.50225  \n9        Yes       Tote    Red             19.059414   67.30516  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>Brand</th>\n      <th>Material</th>\n      <th>Size</th>\n      <th>Compartments</th>\n      <th>Laptop Compartment</th>\n      <th>Waterproof</th>\n      <th>Style</th>\n      <th>Color</th>\n      <th>Weight Capacity (kg)</th>\n      <th>Price</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>500000</td>\n      <td>Under Armour</td>\n      <td>Canvas</td>\n      <td>Small</td>\n      <td>10.0</td>\n      <td>Yes</td>\n      <td>Yes</td>\n      <td>Tote</td>\n      <td>Blue</td>\n      <td>23.882052</td>\n      <td>114.11068</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>500001</td>\n      <td>Puma</td>\n      <td>Polyester</td>\n      <td>Small</td>\n      <td>4.0</td>\n      <td>No</td>\n      <td>Yes</td>\n      <td>Backpack</td>\n      <td>Green</td>\n      <td>11.869095</td>\n      <td>129.74972</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>500002</td>\n      <td>Jansport</td>\n      <td>Polyester</td>\n      <td>Small</td>\n      <td>8.0</td>\n      <td>Yes</td>\n      <td>Yes</td>\n      <td>Tote</td>\n      <td>Red</td>\n      <td>8.092302</td>\n      <td>21.37370</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>500003</td>\n      <td>Nike</td>\n      <td>Nylon</td>\n      <td>Large</td>\n      <td>7.0</td>\n      <td>No</td>\n      <td>No</td>\n      <td>Messenger</td>\n      <td>Pink</td>\n      <td>7.719581</td>\n      <td>48.09209</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>500004</td>\n      <td>Nike</td>\n      <td>Leather</td>\n      <td>Large</td>\n      <td>9.0</td>\n      <td>No</td>\n      <td>Yes</td>\n      <td>Tote</td>\n      <td>Green</td>\n      <td>22.741826</td>\n      <td>77.32461</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>500005</td>\n      <td>Adidas</td>\n      <td>Polyester</td>\n      <td>Medium</td>\n      <td>5.0</td>\n      <td>No</td>\n      <td>No</td>\n      <td>Tote</td>\n      <td>NaN</td>\n      <td>18.834692</td>\n      <td>35.99599</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>500006</td>\n      <td>Jansport</td>\n      <td>Nylon</td>\n      <td>Large</td>\n      <td>5.0</td>\n      <td>Yes</td>\n      <td>Yes</td>\n      <td>Messenger</td>\n      <td>Blue</td>\n      <td>26.882904</td>\n      <td>40.81006</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>500007</td>\n      <td>Adidas</td>\n      <td>Polyester</td>\n      <td>Small</td>\n      <td>9.0</td>\n      <td>Yes</td>\n      <td>No</td>\n      <td>Tote</td>\n      <td>Gray</td>\n      <td>21.716360</td>\n      <td>71.12733</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>500008</td>\n      <td>Adidas</td>\n      <td>Leather</td>\n      <td>Small</td>\n      <td>6.0</td>\n      <td>Yes</td>\n      <td>Yes</td>\n      <td>Tote</td>\n      <td>Green</td>\n      <td>21.849587</td>\n      <td>76.50225</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>500009</td>\n      <td>Puma</td>\n      <td>Nylon</td>\n      <td>Medium</td>\n      <td>2.0</td>\n      <td>No</td>\n      <td>Yes</td>\n      <td>Tote</td>\n      <td>Red</td>\n      <td>19.059414</td>\n      <td>67.30516</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":5},{"cell_type":"code","source":"#checking the number of rows and column present in the data\n\nnum_train_rows, num_train_columns = train.shape\n\nnum_test_rows, num_test_columns = test.shape\n\nnum_extra_rows, num_extra_columns = extra_train.shape\n\nprint(\"Training Data:\")\nprint(f\"Number of Rows: {num_train_rows}\")\nprint(f\"Number of Columns: {num_train_columns}\\n\")\n\nprint(\"Test Data:\")\nprint(f\"Number of Rows: {num_test_rows}\")\nprint(f\"Number of Columns: {num_test_columns}\\n\")\n\nprint(\"Extra Data:\")\nprint(f\"Number of Rows: {num_extra_rows}\")\nprint(f\"Number of Columns: {num_extra_columns}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-22T17:54:11.967930Z","iopub.execute_input":"2025-02-22T17:54:11.968311Z","iopub.status.idle":"2025-02-22T17:54:11.991799Z","shell.execute_reply.started":"2025-02-22T17:54:11.968278Z","shell.execute_reply":"2025-02-22T17:54:11.990187Z"}},"outputs":[{"name":"stdout","text":"Training Data:\nNumber of Rows: 300000\nNumber of Columns: 11\n\nTest Data:\nNumber of Rows: 200000\nNumber of Columns: 10\n\nExtra Data:\nNumber of Rows: 3694318\nNumber of Columns: 11\n","output_type":"stream"}],"execution_count":6},{"cell_type":"markdown","source":"This below code creates a summary table that displays information about missing values, unique values, and data types for features in multiple datasets (train, test, extra_train)","metadata":{}},{"cell_type":"code","source":"# Creating a table for missing values, unique values and data types of the features\n\nmissing_values_train = pd.DataFrame({'Feature': train.columns,\n                              '[TRAIN] No. of Missing Values': train.isnull().sum().values,\n                              '[TRAIN] % of Missing Values': ((train.isnull().sum().values)/len(train)*100)})\n\nmissing_values_test = pd.DataFrame({'Feature': test.columns,\n                             '[TEST] No.of Missing Values': test.isnull().sum().values,\n                             '[TEST] % of Missing Values': ((test.isnull().sum().values)/len(test)*100)})\n\nmissing_values_original = pd.DataFrame({'Feature': extra_train.columns,\n                             '[ORIGINAL] No.of Missing Values': extra_train.isnull().sum().values,\n                             '[ORIGINAL] % of Missing Values': ((extra_train.isnull().sum().values)/len(extra_train)*100)})\n\nunique_values = pd.DataFrame({'Feature': train.columns,\n                              'No. of Unique Values[FROM TRAIN]': train.nunique().values})\nfeature_types = pd.DataFrame({'Feature': train.columns,\n                              'DataType': train.dtypes})\n\nmerged_df = pd.merge(missing_values_train, missing_values_test, on='Feature', how='left')\nmerged_df = pd.merge(merged_df, missing_values_original, on='Feature', how='left')\nmerged_df = pd.merge(merged_df, unique_values, on='Feature', how='left')\nmerged_df = pd.merge(merged_df, feature_types, on='Feature', how='left')\n\nmerged_df","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-22T17:54:11.992969Z","iopub.execute_input":"2025-02-22T17:54:11.993388Z","iopub.status.idle":"2025-02-22T17:54:15.078611Z","shell.execute_reply.started":"2025-02-22T17:54:11.993351Z","shell.execute_reply":"2025-02-22T17:54:15.077243Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/pandas/io/formats/format.py:1458: RuntimeWarning: invalid value encountered in greater\n  has_large_values = (abs_vals > 1e6).any()\n/usr/local/lib/python3.10/dist-packages/pandas/io/formats/format.py:1459: RuntimeWarning: invalid value encountered in less\n  has_small_values = ((abs_vals < 10 ** (-self.digits)) & (abs_vals > 0)).any()\n/usr/local/lib/python3.10/dist-packages/pandas/io/formats/format.py:1459: RuntimeWarning: invalid value encountered in greater\n  has_small_values = ((abs_vals < 10 ** (-self.digits)) & (abs_vals > 0)).any()\n","output_type":"stream"},{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"                 Feature  [TRAIN] No. of Missing Values  \\\n0                     id                              0   \n1                  Brand                           9705   \n2               Material                           8347   \n3                   Size                           6595   \n4           Compartments                              0   \n5     Laptop Compartment                           7444   \n6             Waterproof                           7050   \n7                  Style                           7970   \n8                  Color                           9950   \n9   Weight Capacity (kg)                            138   \n10                 Price                              0   \n\n    [TRAIN] % of Missing Values  [TEST] No.of Missing Values  \\\n0                      0.000000                          0.0   \n1                      3.235000                       6227.0   \n2                      2.782333                       5613.0   \n3                      2.198333                       4381.0   \n4                      0.000000                          0.0   \n5                      2.481333                       4962.0   \n6                      2.350000                       4811.0   \n7                      2.656667                       5153.0   \n8                      3.316667                       6785.0   \n9                      0.046000                         77.0   \n10                     0.000000                          NaN   \n\n    [TEST] % of Missing Values  [ORIGINAL] No.of Missing Values  \\\n0                       0.0000                                0   \n1                       3.1135                           117053   \n2                       2.8065                           102615   \n3                       2.1905                            81190   \n4                       0.0000                                0   \n5                       2.4810                            91089   \n6                       2.4055                            87274   \n7                       2.5765                            96210   \n8                       3.3925                           123667   \n9                       0.0385                             1670   \n10                         NaN                                0   \n\n    [ORIGINAL] % of Missing Values  No. of Unique Values[FROM TRAIN] DataType  \n0                         0.000000                            300000    int64  \n1                         3.168460                                 5   object  \n2                         2.777644                                 4   object  \n3                         2.197699                                 3   object  \n4                         0.000000                                10  float64  \n5                         2.465651                                 2   object  \n6                         2.362385                                 2   object  \n7                         2.604270                                 3   object  \n8                         3.347492                                 6   object  \n9                         0.045205                            181596  float64  \n10                        0.000000                             48212  float64  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Feature</th>\n      <th>[TRAIN] No. of Missing Values</th>\n      <th>[TRAIN] % of Missing Values</th>\n      <th>[TEST] No.of Missing Values</th>\n      <th>[TEST] % of Missing Values</th>\n      <th>[ORIGINAL] No.of Missing Values</th>\n      <th>[ORIGINAL] % of Missing Values</th>\n      <th>No. of Unique Values[FROM TRAIN]</th>\n      <th>DataType</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>id</td>\n      <td>0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0000</td>\n      <td>0</td>\n      <td>0.000000</td>\n      <td>300000</td>\n      <td>int64</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Brand</td>\n      <td>9705</td>\n      <td>3.235000</td>\n      <td>6227.0</td>\n      <td>3.1135</td>\n      <td>117053</td>\n      <td>3.168460</td>\n      <td>5</td>\n      <td>object</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Material</td>\n      <td>8347</td>\n      <td>2.782333</td>\n      <td>5613.0</td>\n      <td>2.8065</td>\n      <td>102615</td>\n      <td>2.777644</td>\n      <td>4</td>\n      <td>object</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Size</td>\n      <td>6595</td>\n      <td>2.198333</td>\n      <td>4381.0</td>\n      <td>2.1905</td>\n      <td>81190</td>\n      <td>2.197699</td>\n      <td>3</td>\n      <td>object</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Compartments</td>\n      <td>0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0000</td>\n      <td>0</td>\n      <td>0.000000</td>\n      <td>10</td>\n      <td>float64</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>Laptop Compartment</td>\n      <td>7444</td>\n      <td>2.481333</td>\n      <td>4962.0</td>\n      <td>2.4810</td>\n      <td>91089</td>\n      <td>2.465651</td>\n      <td>2</td>\n      <td>object</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>Waterproof</td>\n      <td>7050</td>\n      <td>2.350000</td>\n      <td>4811.0</td>\n      <td>2.4055</td>\n      <td>87274</td>\n      <td>2.362385</td>\n      <td>2</td>\n      <td>object</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>Style</td>\n      <td>7970</td>\n      <td>2.656667</td>\n      <td>5153.0</td>\n      <td>2.5765</td>\n      <td>96210</td>\n      <td>2.604270</td>\n      <td>3</td>\n      <td>object</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>Color</td>\n      <td>9950</td>\n      <td>3.316667</td>\n      <td>6785.0</td>\n      <td>3.3925</td>\n      <td>123667</td>\n      <td>3.347492</td>\n      <td>6</td>\n      <td>object</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>Weight Capacity (kg)</td>\n      <td>138</td>\n      <td>0.046000</td>\n      <td>77.0</td>\n      <td>0.0385</td>\n      <td>1670</td>\n      <td>0.045205</td>\n      <td>181596</td>\n      <td>float64</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>Price</td>\n      <td>0</td>\n      <td>0.000000</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>0.000000</td>\n      <td>48212</td>\n      <td>float64</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":7},{"cell_type":"code","source":"#Count the duplicates in the train test and extra train \ntrain_duplicates = train.duplicated().sum()\ntest_duplicates = test.duplicated().sum()\nextra_duplicates = extra_train.duplicated().sum()\n\nprint(f\"Number of duplicate rows in train data: {train_duplicates}\")\nprint(f\"Number of duplicate rows in test data: {test_duplicates}\")\nprint(f\"Number of duplicate rows in extra train data: {extra_duplicates}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-22T17:54:15.079682Z","iopub.execute_input":"2025-02-22T17:54:15.079961Z","iopub.status.idle":"2025-02-22T17:54:19.547565Z","shell.execute_reply.started":"2025-02-22T17:54:15.079935Z","shell.execute_reply":"2025-02-22T17:54:19.546559Z"}},"outputs":[{"name":"stdout","text":"Number of duplicate rows in train data: 0\nNumber of duplicate rows in test data: 0\nNumber of duplicate rows in extra train data: 0\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"train.describe().T","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-22T17:54:19.550686Z","iopub.execute_input":"2025-02-22T17:54:19.550976Z","iopub.status.idle":"2025-02-22T17:54:19.624756Z","shell.execute_reply.started":"2025-02-22T17:54:19.550953Z","shell.execute_reply":"2025-02-22T17:54:19.623617Z"}},"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"                         count           mean           std   min  \\\nid                    300000.0  149999.500000  86602.684716   0.0   \nCompartments          300000.0       5.443590      2.890766   1.0   \nWeight Capacity (kg)  299862.0      18.029994      6.966914   5.0   \nPrice                 300000.0      81.411107     39.039340  15.0   \n\n                               25%            50%            75%       max  \nid                    74999.750000  149999.500000  224999.250000  299999.0  \nCompartments              3.000000       5.000000       8.000000      10.0  \nWeight Capacity (kg)     12.097867      18.068614      24.002375      30.0  \nPrice                    47.384620      80.956120     115.018160     150.0  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>count</th>\n      <th>mean</th>\n      <th>std</th>\n      <th>min</th>\n      <th>25%</th>\n      <th>50%</th>\n      <th>75%</th>\n      <th>max</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>id</th>\n      <td>300000.0</td>\n      <td>149999.500000</td>\n      <td>86602.684716</td>\n      <td>0.0</td>\n      <td>74999.750000</td>\n      <td>149999.500000</td>\n      <td>224999.250000</td>\n      <td>299999.0</td>\n    </tr>\n    <tr>\n      <th>Compartments</th>\n      <td>300000.0</td>\n      <td>5.443590</td>\n      <td>2.890766</td>\n      <td>1.0</td>\n      <td>3.000000</td>\n      <td>5.000000</td>\n      <td>8.000000</td>\n      <td>10.0</td>\n    </tr>\n    <tr>\n      <th>Weight Capacity (kg)</th>\n      <td>299862.0</td>\n      <td>18.029994</td>\n      <td>6.966914</td>\n      <td>5.0</td>\n      <td>12.097867</td>\n      <td>18.068614</td>\n      <td>24.002375</td>\n      <td>30.0</td>\n    </tr>\n    <tr>\n      <th>Price</th>\n      <td>300000.0</td>\n      <td>81.411107</td>\n      <td>39.039340</td>\n      <td>15.0</td>\n      <td>47.384620</td>\n      <td>80.956120</td>\n      <td>115.018160</td>\n      <td>150.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":9},{"cell_type":"markdown","source":"EDA","metadata":{}},{"cell_type":"code","source":"train = pd.concat([train, extra_train], ignore_index=True)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-22T17:54:19.626230Z","iopub.execute_input":"2025-02-22T17:54:19.626523Z","iopub.status.idle":"2025-02-22T17:54:20.098294Z","shell.execute_reply.started":"2025-02-22T17:54:19.626499Z","shell.execute_reply":"2025-02-22T17:54:20.097058Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"numerical_variables = [\"Weight Capacity (kg)\"]\ntarget_variable = \"Price\"\ncategorical_variables = ['Brand', 'Material', 'Size', 'Compartments', 'Laptop Compartment','Waterproof', 'Style', 'Color']","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-22T17:54:20.099453Z","iopub.execute_input":"2025-02-22T17:54:20.099833Z","iopub.status.idle":"2025-02-22T17:54:20.104940Z","shell.execute_reply.started":"2025-02-22T17:54:20.099794Z","shell.execute_reply":"2025-02-22T17:54:20.103887Z"}},"outputs":[],"execution_count":11},{"cell_type":"markdown","source":"Data Imputation (Handling missing values)\n\nUnderstanding Each Feature and Missing Data Handling\n1️⃣ Brand (~3.24% missing in train, ~3.11% in test)\nUnique Values: Jansport, Under Armour, Nike, Adidas, Puma, NaN\nImputation Strategy: Since it's categorical with only 5 unique brands, we can impute missing values with the mode (most frequent brand).\n2️⃣ Material (~2.78% missing in train, ~2.81% in test)\nUnique Values: Leather, Canvas, Nylon, Polyester, NaN\nImputation Strategy: Mode imputation works best here since materials are limited categories.\n3️⃣ Size (~2.20% missing in train, ~2.19% in test)\nUnique Values: Medium, Small, Large, NaN\nImputation Strategy: Since it's a well-defined categorical variable, we use mode imputation.\n4️⃣ Compartments (✅ No missing values)\nUnique Values: 10 unique numerical values\nImputation Strategy: ✅ No action needed.\n5️⃣ Laptop Compartment (~2.48% missing in train, ~2.48% in test)\nUnique Values: Yes, No, NaN\nImputation Strategy: Since it's a binary categorical variable, we use mode imputation.\n6️⃣ Waterproof (~2.35% missing in train, ~2.41% in test)\nUnique Values: Yes, No, NaN\nImputation Strategy: Mode imputation is best.\n7️⃣ Style (~2.66% missing in train, ~2.58% in test)\nUnique Values: Tote, Messenger, Backpack, NaN\nImputation Strategy: Mode imputation.\n8️⃣ Color (~3.32% missing in train, ~3.39% in test)\nUnique Values: Black, Green, Red, Blue, Gray, Pink, NaN\nImputation Strategy: Mode imputation.\n9️⃣ Weight Capacity (kg) (~0.05% missing in train, ~0.04% in test)\nUnique Values: Numeric\nImputation Strategy: Since it is a continuous numerical variable, we use median imputation to prevent extreme values from affecting the distribution.","metadata":{}},{"cell_type":"code","source":"# Define imputation strategies\ncategorical_features = [\"Brand\", \"Material\", \"Size\", \"Laptop Compartment\", \"Waterproof\", \"Style\", \"Color\"]\nnumerical_features = [\"Weight Capacity (kg)\"]\n\n# Fill categorical missing values with mode (most frequent value)\nfor col in categorical_features:\n    train[col].fillna(train[col].mode()[0], inplace=True)\n    test[col].fillna(test[col].mode()[0], inplace=True)\n\n# Fill numerical missing values with median\nfor col in numerical_features:\n    train[col].fillna(train[col].median(), inplace=True)\n    test[col].fillna(test[col].median(), inplace=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-22T17:54:20.106267Z","iopub.execute_input":"2025-02-22T17:54:20.106625Z","iopub.status.idle":"2025-02-22T17:54:24.141240Z","shell.execute_reply.started":"2025-02-22T17:54:20.106598Z","shell.execute_reply":"2025-02-22T17:54:24.140028Z"}},"outputs":[{"name":"stderr","text":"<ipython-input-12-cb2c177abb52>:7: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\nThe behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n\nFor example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n\n\n  train[col].fillna(train[col].mode()[0], inplace=True)\n<ipython-input-12-cb2c177abb52>:8: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\nThe behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n\nFor example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n\n\n  test[col].fillna(test[col].mode()[0], inplace=True)\n<ipython-input-12-cb2c177abb52>:12: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\nThe behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n\nFor example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n\n\n  train[col].fillna(train[col].median(), inplace=True)\n<ipython-input-12-cb2c177abb52>:13: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\nThe behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n\nFor example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n\n\n  test[col].fillna(test[col].median(), inplace=True)\n","output_type":"stream"}],"execution_count":12},{"cell_type":"code","source":"train.isnull().sum()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-22T17:54:24.143599Z","iopub.execute_input":"2025-02-22T17:54:24.143945Z","iopub.status.idle":"2025-02-22T17:54:25.543906Z","shell.execute_reply.started":"2025-02-22T17:54:24.143916Z","shell.execute_reply":"2025-02-22T17:54:25.542608Z"}},"outputs":[{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"id                      0\nBrand                   0\nMaterial                0\nSize                    0\nCompartments            0\nLaptop Compartment      0\nWaterproof              0\nStyle                   0\nColor                   0\nWeight Capacity (kg)    0\nPrice                   0\ndtype: int64"},"metadata":{}}],"execution_count":13},{"cell_type":"code","source":"# Display all column names\nprint(X_train.columns)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-22T17:54:54.548156Z","iopub.execute_input":"2025-02-22T17:54:54.548526Z","iopub.status.idle":"2025-02-22T17:54:54.553823Z","shell.execute_reply.started":"2025-02-22T17:54:54.548498Z","shell.execute_reply":"2025-02-22T17:54:54.552555Z"}},"outputs":[{"name":"stdout","text":"Index(['id', 'Brand', 'Material', 'Size', 'Compartments', 'Laptop Compartment',\n       'Waterproof', 'Style', 'Color', 'Weight Capacity (kg)'],\n      dtype='object')\n","output_type":"stream"}],"execution_count":24},{"cell_type":"code","source":"# List of columns you want to check unique values for\ncolumns_to_check = ['Brand', 'Material', 'Size', 'Compartments', 'Laptop Compartment',\n                    'Waterproof', 'Style', 'Color', 'Weight Capacity (kg)']\n\n# Loop through each column and print unique values\nfor col in columns_to_check:\n    if col in X_train.columns:\n        print(f\"Unique values in '{col}':\")\n        print(X_train[col].unique())\n        print(\"=\"*50)\n    else:\n        print(f\"Column '{col}' not found in the dataset.\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-22T17:55:36.957181Z","iopub.execute_input":"2025-02-22T17:55:36.957614Z","iopub.status.idle":"2025-02-22T17:55:38.453228Z","shell.execute_reply.started":"2025-02-22T17:55:36.957582Z","shell.execute_reply":"2025-02-22T17:55:38.452176Z"}},"outputs":[{"name":"stdout","text":"Unique values in 'Brand':\n['Under Armour' 'Adidas' 'Puma' 'Jansport' 'Nike']\n==================================================\nUnique values in 'Material':\n['Nylon' 'Polyester' 'Leather' 'Canvas']\n==================================================\nUnique values in 'Size':\n['Large' 'Medium' 'Small']\n==================================================\nUnique values in 'Compartments':\n[ 5.  7.  3.  6. 10.  4.  2.  1.  9.  8.]\n==================================================\nUnique values in 'Laptop Compartment':\n['Yes' 'No']\n==================================================\nUnique values in 'Waterproof':\n['Yes' 'No']\n==================================================\nUnique values in 'Style':\n['Tote' 'Backpack' 'Messenger']\n==================================================\nUnique values in 'Color':\n['Blue' 'Black' 'Green' 'Red' 'Gray' 'Pink']\n==================================================\nUnique values in 'Weight Capacity (kg)':\n[17.90855234 13.08145247 19.55185251 ... 23.50389097 16.025853\n 16.60998863]\n==================================================\n","output_type":"stream"}],"execution_count":25},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\n# Split the dataset into train and test sets\nX = train.drop(columns='Price')  # Assuming 'Price' is the target\ny = train['Price']\n\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-22T17:54:25.545007Z","iopub.execute_input":"2025-02-22T17:54:25.545382Z","iopub.status.idle":"2025-02-22T17:54:25.868918Z","shell.execute_reply.started":"2025-02-22T17:54:25.545355Z","shell.execute_reply":"2025-02-22T17:54:25.867732Z"}},"outputs":[],"execution_count":14},{"cell_type":"code","source":"# Define categorical and numerical columns\ncategorical_cols = X.select_dtypes(include=['object']).columns\nnumerical_cols = X.select_dtypes(exclude=['object']).columns\nprint(categorical_cols)\nprint(numerical_cols)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-22T17:54:25.870350Z","iopub.execute_input":"2025-02-22T17:54:25.870752Z","iopub.status.idle":"2025-02-22T17:54:27.242789Z","shell.execute_reply.started":"2025-02-22T17:54:25.870713Z","shell.execute_reply":"2025-02-22T17:54:27.241499Z"}},"outputs":[{"name":"stdout","text":"Index(['Brand', 'Material', 'Size', 'Laptop Compartment', 'Waterproof',\n       'Style', 'Color'],\n      dtype='object')\nIndex(['id', 'Compartments', 'Weight Capacity (kg)'], dtype='object')\n","output_type":"stream"}],"execution_count":15},{"cell_type":"code","source":"from sklearn.preprocessing import OneHotEncoder, StandardScaler\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.metrics import make_scorer, mean_squared_error\nfrom lightgbm import LGBMRegressor","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-22T17:54:27.243883Z","iopub.execute_input":"2025-02-22T17:54:27.244295Z","iopub.status.idle":"2025-02-22T17:54:27.263430Z","shell.execute_reply.started":"2025-02-22T17:54:27.244256Z","shell.execute_reply":"2025-02-22T17:54:27.262372Z"}},"outputs":[],"execution_count":16},{"cell_type":"code","source":"from sklearn.pipeline import Pipeline\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.preprocessing import StandardScaler, OneHotEncoder\nimport joblib\n\ncat_cols=train.select_dtypes(include='object').columns.tolist()\ncat_cols\n\n# Define the pipeline components\nweight_capacity_pipe = Pipeline(steps=[('scaler', StandardScaler())])\n\n# Define the column transformer for preprocessing\npreprocessor = ColumnTransformer(\n    transformers=[\n        ('weight_capacity_pipe', weight_capacity_pipe, ['Weight Capacity (kg)']),  # Scaling numeric column\n        ('cat_pipeline', Pipeline(steps=[  # One-Hot Encoding categorical features\n            ('encoder', OneHotEncoder())\n        ]), cat_cols)\n    ],\n    remainder='passthrough'\n)\n\n# Save the preprocessor pipeline to a .pkl file\njoblib.dump(preprocessor, 'preprocessor_pipeline.pkl')\nprint(\"📂 Preprocessor pipeline saved to 'preprocessor_pipeline.pkl'.\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-22T17:54:27.264548Z","iopub.execute_input":"2025-02-22T17:54:27.264916Z","iopub.status.idle":"2025-02-22T17:54:28.541903Z","shell.execute_reply.started":"2025-02-22T17:54:27.264879Z","shell.execute_reply":"2025-02-22T17:54:28.540711Z"}},"outputs":[{"name":"stdout","text":"📂 Preprocessor pipeline saved to 'preprocessor_pipeline.pkl'.\n","output_type":"stream"}],"execution_count":17},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nX_train,X_test,y_train,y_test= train_test_split(train.drop(columns='Price'),train['Price'],test_size=0.2)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-22T17:54:28.542969Z","iopub.execute_input":"2025-02-22T17:54:28.543437Z","iopub.status.idle":"2025-02-22T17:54:32.534350Z","shell.execute_reply.started":"2025-02-22T17:54:28.543398Z","shell.execute_reply":"2025-02-22T17:54:32.533353Z"}},"outputs":[],"execution_count":18},{"cell_type":"code","source":"# import joblib\n# from sklearn.pipeline import Pipeline\n# from sklearn.model_selection import KFold\n# from sklearn.metrics import mean_squared_error\n# import numpy as np\n# import pandas as pd\n# from sklearn.linear_model import LinearRegression  # Import Linear Regression\n\n# # Ensure preprocessor is defined (Replace with actual preprocessing steps)\n# assert 'preprocessor' in globals(), \"Define 'preprocessor' before using it in the pipeline.\"\n\n# # Initialize KFold\n# n_folds = 5\n# kf = KFold(n_splits=n_folds, shuffle=True, random_state=42)\n\n# # DataFrame to store out-of-fold predictions\n# oof_df = pd.DataFrame(columns=['ID', 'Actual', 'OOF_Pred_LR', 'Fold'])\n\n# # Ensure X_train and y_train are defined before using them\n# assert 'X_train' in globals() and 'y_train' in globals(), \"Ensure X_train and y_train are defined.\"\n\n# # Convert X_train and y_train to DataFrames if they aren't already\n# X_train = pd.DataFrame(X_train)\n# y_train = pd.Series(y_train, name='Price')  # Ensure y_train is explicitly set to 'Price'\n\n# # Initialize array to store out-of-fold predictions\n# oof_preds = np.zeros(len(X_train))\n\n# # K-Fold Cross-Validation Loop\n# for fold, (train_idx, val_idx) in enumerate(kf.split(X_train, y_train), start=1):\n#     print(f\"\\n🔄 Training Fold {fold}/{n_folds}...\")\n\n#     # Split data into training and validation sets\n#     X_tr, X_val = X_train.iloc[train_idx], X_train.iloc[val_idx]\n#     y_tr, y_val = y_train.iloc[train_idx], y_train.iloc[val_idx]\n\n#     # Create pipeline with preprocessor and Linear Regression model\n#     pipeline = Pipeline(steps=[\n#         ('preprocessor', preprocessor),  # Replace with actual preprocessor\n#         ('model', LinearRegression())  # Linear Regression model\n#     ])\n\n#     # Train the model\n#     pipeline.fit(X_tr, y_tr)\n\n#     # Save model for the current fold\n#     joblib.dump(pipeline, f'linear_regression_fold_{fold}.pkl')\n#     print(f\"💾 Model for Fold {fold} saved as 'linear_regression_fold_{fold}.pkl'\")\n\n#     # Predict on validation set (OOF predictions)\n#     y_val_pred = pipeline.predict(X_val)\n#     oof_preds[val_idx] = y_val_pred  # Store OOF predictions\n\n#     # Compute fold RMSE\n#     fold_rmse = mean_squared_error(y_val, y_val_pred, squared=False)\n#     print(f\"✅ Fold {fold} RMSE: {fold_rmse:.4f}\")\n\n#     # Store fold results in DataFrame\n#     fold_df = pd.DataFrame({\n#         'ID': X_train.index[val_idx],  # Assuming index represents unique IDs\n#         'Actual': y_val.values,\n#         'OOF_Pred_LR': y_val_pred,\n#         'Fold': fold\n#     })\n\n#     oof_df = pd.concat([oof_df, fold_df], ignore_index=True)\n\n# # Compute overall OOF RMSE\n# oof_rmse = mean_squared_error(y_train, oof_preds, squared=False)\n# print(f\"\\n🏆 Overall OOF RMSE: {oof_rmse:.4f}\")\n\n# # Save OOF predictions to CSV\n# oof_df.to_csv('oof_predictions_lr.csv', index=False)\n# print(\"📂 OOF predictions saved to 'oof_predictions_lr.csv'.\")\n\n# # Train final model on the entire dataset\n# final_pipeline = Pipeline(steps=[\n#     ('preprocessor', preprocessor),  # Replace with actual preprocessor\n#     ('model', LinearRegression())  # Linear Regression model\n# ])\n# final_pipeline.fit(X_train, y_train)\n\n# # Save final model\n# joblib.dump(final_pipeline, 'linear_regression_final.pkl')\n# print(\"💾 Final model saved as 'linear_regression_final.pkl'.\")\n\n# # Display first few rows of OOF predictions\n# oof_df.reset_index(drop=True, inplace=True)\n# print(oof_df.head())\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-22T17:54:32.535192Z","iopub.execute_input":"2025-02-22T17:54:32.535558Z","iopub.status.idle":"2025-02-22T17:54:32.540949Z","shell.execute_reply.started":"2025-02-22T17:54:32.535521Z","shell.execute_reply":"2025-02-22T17:54:32.539860Z"}},"outputs":[],"execution_count":19},{"cell_type":"code","source":"# # Make predictions on the test set\n# predictions = pipeline.predict(test)\n\n# # Create the submission DataFrame\n# submission = pd.DataFrame({\n#     'id': test['id'],         # Ensure 'id' exists in the test set\n#     'Price': predictions      # Use predictions on the test set\n# })\n\n# # Save the DataFrame to a CSV file\n# submission.to_csv('submission200.csv', index=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-22T17:54:32.541787Z","iopub.execute_input":"2025-02-22T17:54:32.542194Z","iopub.status.idle":"2025-02-22T17:54:32.564862Z","shell.execute_reply.started":"2025-02-22T17:54:32.542149Z","shell.execute_reply":"2025-02-22T17:54:32.563834Z"}},"outputs":[],"execution_count":20},{"cell_type":"code","source":"# from sklearn.compose import ColumnTransformer\n# from sklearn.preprocessing import OneHotEncoder\n# from sklearn.impute import SimpleImputer\n# from sklearn.pipeline import Pipeline\n# from sklearn.model_selection import KFold, GridSearchCV\n# from sklearn.metrics import mean_squared_error\n# from sklearn.linear_model import Ridge\n# import numpy as np\n# import pandas as pd\n\n# # Ensure preprocessor is defined (Replace with actual preprocessing steps)\n# assert 'preprocessor' in globals(), \"Define 'preprocessor' before using it in the pipeline.\"\n\n# # Define columns\n# numeric_features = X_train.select_dtypes(include=['int64', 'float64']).columns\n# categorical_features = X_train.select_dtypes(include=['object']).columns\n\n# # Create numeric transformer\n# numeric_transformer = Pipeline(steps=[\n#     ('imputer', SimpleImputer(strategy='mean'))  # Impute missing values with mean for numeric features\n# ])\n\n# # Create categorical transformer\n# categorical_transformer = Pipeline(steps=[\n#     ('imputer', SimpleImputer(strategy='most_frequent')),  # Impute missing values with most frequent for categorical features\n#     ('onehot', OneHotEncoder(handle_unknown='ignore'))  # One-hot encoding for categorical features\n# ])\n\n# # Combine both transformations using ColumnTransformer\n# preprocessor = ColumnTransformer(\n#     transformers=[\n#         ('num', numeric_transformer, numeric_features),\n#         ('cat', categorical_transformer, categorical_features)\n#     ])\n\n# # Initialize KFold\n# n_folds = 5\n# kf = KFold(n_splits=n_folds, shuffle=True, random_state=42)\n\n# # DataFrame to store out-of-fold predictions\n# oof_df = pd.DataFrame(columns=['ID', 'Actual', 'OOF_Pred_Ridge', 'Fold'])\n\n# # Convert X_train and y_train to DataFrames if they aren't already\n# X_train = pd.DataFrame(X_train)\n# y_train = pd.Series(y_train)\n\n# # Initialize array to store out-of-fold predictions\n# oof_preds = np.zeros(len(X_train))\n\n# # Ridge hyperparameter grid for tuning alpha\n# param_grid = {\n#     'model__alpha': [0.01, 0.1, 1, 10, 100]  # Regularization strength (alpha)\n# }\n\n# # K-Fold Cross-Validation Loop\n# for fold, (train_idx, val_idx) in enumerate(kf.split(X_train, y_train), start=1):\n#     print(f\"\\n🔄 Training Fold {fold}/{n_folds}...\")\n\n#     # Split data into training and validation sets\n#     X_tr, X_val = X_train.iloc[train_idx], X_train.iloc[val_idx]\n#     y_tr, y_val = y_train.iloc[train_idx], y_train.iloc[val_idx]\n\n#     # Create pipeline with imputation, preprocessor, and Ridge regression model\n#     pipeline = Pipeline(steps=[\n#         ('preprocessor', preprocessor),  # Apply transformations to numeric and categorical features\n#         ('model', Ridge())  # Use Ridge regression instead of Linear Regression\n#     ])\n\n#     # Set up GridSearchCV for hyperparameter tuning\n#     grid_search = GridSearchCV(pipeline, param_grid, cv=5, scoring='neg_mean_squared_error')\n\n#     # Train the model using grid search\n#     grid_search.fit(X_tr, y_tr)\n\n#     # Best model after tuning\n#     best_model = grid_search.best_estimator_\n\n#     # Predict on validation set (OOF predictions) using the best model\n#     y_val_pred = best_model.predict(X_val)\n#     oof_preds[val_idx] = y_val_pred  # Store OOF predictions\n\n#     # Compute fold RMSE\n#     fold_rmse = mean_squared_error(y_val, y_val_pred, squared=False)\n#     print(f\"✅ Fold {fold} RMSE: {fold_rmse:.4f}\")\n\n#     # Store fold results in DataFrame\n#     fold_df = pd.DataFrame({\n#         'ID': X_train.index[val_idx],  # Assuming index represents unique IDs\n#         'Actual': y_val.values,\n#         'OOF_Pred_Ridge': y_val_pred,\n#         'Fold': fold\n#     })\n\n#     oof_df = pd.concat([oof_df, fold_df], ignore_index=True)\n\n# # Compute overall OOF RMSE\n# oof_rmse = mean_squared_error(y_train, oof_preds, squared=False)\n# print(f\"\\n🏆 Overall OOF RMSE: {oof_rmse:.4f}\")\n\n# # Save OOF predictions to CSV\n# oof_df.to_csv('oof_predictions_ridge.csv', index=False)\n# print(\"📂 OOF predictions saved to 'oof_predictions_ridge.csv'.\")\n\n# # Display first few rows of OOF predictions\n# oof_df.reset_index(drop=True, inplace=True)\n# print(oof_df.head())\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-22T17:54:32.565845Z","iopub.execute_input":"2025-02-22T17:54:32.566198Z","iopub.status.idle":"2025-02-22T17:54:32.582711Z","shell.execute_reply.started":"2025-02-22T17:54:32.566156Z","shell.execute_reply":"2025-02-22T17:54:32.581841Z"}},"outputs":[],"execution_count":21},{"cell_type":"code","source":"# import joblib\n\n# # Save the best model to a .pkl file\n# joblib.dump(best_model, 'ridge_regression_model.pkl')\n# print(\"✅ Model saved as 'ridge_regression_model.pkl'\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-22T17:54:32.583651Z","iopub.execute_input":"2025-02-22T17:54:32.583972Z","iopub.status.idle":"2025-02-22T17:54:32.605967Z","shell.execute_reply.started":"2025-02-22T17:54:32.583946Z","shell.execute_reply":"2025-02-22T17:54:32.604898Z"}},"outputs":[],"execution_count":22},{"cell_type":"code","source":"# # After training and obtaining out-of-fold predictions (as you're already doing)\n# # Make predictions on the test set (Replace 'test' with your actual test DataFrame)\n# test = pd.DataFrame(test)  # Ensure test is a DataFrame\n# assert 'id' in test.columns, \"The test DataFrame must contain an 'id' column.\"\n\n# # Make predictions on the test set\n# test_predictions = best_model.predict(test)  # Make predictions using the best model after GridSearchCV\n\n# # Create the submission DataFrame\n# submission = pd.DataFrame({\n#     'id': test['id'],         # Ensure 'id' exists in the test set\n#     'Price': test_predictions  # Use predictions on the test set\n# })\n\n# # Save the DataFrame to a CSV file\n# submission.to_csv('submissiono0123.csv', index=False)\n\n# # Save the OOF predictions DataFrame to a CSV file\n# oof_df.to_csv('oof_predictions_ridge.csv', index=False)\n# print(\"📂 OOF predictions saved to 'oof_predictions_ridge.csv'.\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-22T17:54:32.606948Z","iopub.execute_input":"2025-02-22T17:54:32.607294Z","iopub.status.idle":"2025-02-22T17:54:32.630499Z","shell.execute_reply.started":"2025-02-22T17:54:32.607260Z","shell.execute_reply":"2025-02-22T17:54:32.629228Z"}},"outputs":[],"execution_count":23}]}