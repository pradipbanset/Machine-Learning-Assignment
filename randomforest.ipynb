{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":10762458,"sourceType":"datasetVersion","datasetId":6675858}],"dockerImageVersionId":30887,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-02-22T16:04:49.965537Z","iopub.execute_input":"2025-02-22T16:04:49.966112Z","iopub.status.idle":"2025-02-22T16:04:51.242701Z","shell.execute_reply.started":"2025-02-22T16:04:49.966070Z","shell.execute_reply":"2025-02-22T16:04:51.241465Z"}},"outputs":[{"name":"stdout","text":"/kaggle/input/backpack/sample_submission.csv\n/kaggle/input/backpack/train.csv\n/kaggle/input/backpack/test.csv\n/kaggle/input/backpack/training_extra.csv\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import pandas as pd\nfrom sklearn.model_selection import train_test_split, GridSearchCV\nfrom sklearn.preprocessing import LabelEncoder, StandardScaler\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.metrics import mean_squared_error\nimport numpy as np\n\n# Load datasets\ntrain = pd.read_csv(\"/kaggle/input/backpack/train.csv\")\ntest = pd.read_csv(\"/kaggle/input/backpack/test.csv\")\ntrain_extra = pd.read_csv(\"/kaggle/input/backpack/training_extra.csv\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-22T16:04:51.244072Z","iopub.execute_input":"2025-02-22T16:04:51.244755Z","iopub.status.idle":"2025-02-22T16:05:03.840671Z","shell.execute_reply.started":"2025-02-22T16:04:51.244710Z","shell.execute_reply":"2025-02-22T16:05:03.839445Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"import sklearn\nprint(sklearn.__version__)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-22T16:05:36.351516Z","iopub.execute_input":"2025-02-22T16:05:36.351895Z","iopub.status.idle":"2025-02-22T16:05:36.357862Z","shell.execute_reply.started":"2025-02-22T16:05:36.351868Z","shell.execute_reply":"2025-02-22T16:05:36.356388Z"}},"outputs":[{"name":"stdout","text":"1.2.2\n","output_type":"stream"}],"execution_count":11},{"cell_type":"code","source":"train = pd.concat([train, train_extra], ignore_index=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-22T16:05:03.841825Z","iopub.execute_input":"2025-02-22T16:05:03.842246Z","iopub.status.idle":"2025-02-22T16:05:04.335122Z","shell.execute_reply.started":"2025-02-22T16:05:03.842202Z","shell.execute_reply":"2025-02-22T16:05:04.333892Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"# Handle missing values\ncategorical_cols = [\"Brand\", \"Material\", \"Size\", \"Laptop Compartment\", \"Waterproof\", \"Style\", \"Color\"]\nnumerical_cols = [\"Compartments\", \"Weight Capacity (kg)\"]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-22T16:05:04.338045Z","iopub.execute_input":"2025-02-22T16:05:04.338382Z","iopub.status.idle":"2025-02-22T16:05:04.343782Z","shell.execute_reply.started":"2025-02-22T16:05:04.338356Z","shell.execute_reply":"2025-02-22T16:05:04.341961Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"# Fill missing categorical values with mode\ndef fill_mode(df, columns):\n    for col in columns:\n        df[col] = df[col].fillna(df[col].mode()[0])\n\nfill_mode(train, categorical_cols)\nfill_mode(test, categorical_cols)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-22T16:05:04.345586Z","iopub.execute_input":"2025-02-22T16:05:04.346214Z","iopub.status.idle":"2025-02-22T16:05:08.819981Z","shell.execute_reply.started":"2025-02-22T16:05:04.346138Z","shell.execute_reply":"2025-02-22T16:05:08.818813Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"# Fill missing numerical values with median\ndef fill_median(df, columns):\n    for col in columns:\n        df[col] = df[col].fillna(df[col].median())\n\nfill_median(train, numerical_cols)\nfill_median(test, numerical_cols)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-22T16:05:08.821045Z","iopub.execute_input":"2025-02-22T16:05:08.821339Z","iopub.status.idle":"2025-02-22T16:05:09.050304Z","shell.execute_reply.started":"2025-02-22T16:05:08.821315Z","shell.execute_reply":"2025-02-22T16:05:09.048996Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"# Encode categorical variables\nlabel_encoders = {}\nfor col in categorical_cols:\n    le = LabelEncoder()\n    train[col] = le.fit_transform(train[col])\n    test[col] = le.transform(test[col])\n    label_encoders[col] = le\n\n# Define features and target\nfeatures = categorical_cols + numerical_cols\nX = train[features]\ny = train[\"Price\"]\nX_test = test[features]\n\n# Standardize numerical features\nscaler = StandardScaler()\nX.loc[:, numerical_cols] = scaler.fit_transform(X[numerical_cols])\nX_test.loc[:, numerical_cols] = scaler.transform(X_test[numerical_cols])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-22T16:05:09.051614Z","iopub.execute_input":"2025-02-22T16:05:09.052047Z","iopub.status.idle":"2025-02-22T16:05:15.632066Z","shell.execute_reply.started":"2025-02-22T16:05:09.052003Z","shell.execute_reply":"2025-02-22T16:05:15.630906Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"# from sklearn.model_selection import KFold\n# from sklearn.ensemble import RandomForestRegressor\n# from sklearn.metrics import mean_squared_error\n# import numpy as np\n# import joblib\n# import pandas as pd\n\n# # Define the best hyperparameters\n# best_params = {\n#     'n_estimators': 200,  # Optimized number of trees\n#     'max_depth': 8,  # Optimized max depth\n#     'min_samples_split': 3,  # Optimized min samples to split\n#     'min_samples_leaf': 9,  # Optimized min samples per leaf\n#     'max_features': 'log2',  # Optimized feature selection strategy\n#     'bootstrap': False  # Optimized bootstrapping option\n# }\n\n# # Define the number of folds\n# n_folds = 5\n# kf = KFold(n_splits=n_folds, shuffle=True, random_state=42)\n\n# # Initialize Random Forest Regressor with optimized parameters\n# rf_model = RandomForestRegressor(\n#     n_estimators=best_params['n_estimators'],\n#     max_depth=best_params['max_depth'],\n#     min_samples_split=best_params['min_samples_split'],\n#     min_samples_leaf=best_params['min_samples_leaf'],\n#     max_features=best_params['max_features'],\n#     bootstrap=best_params['bootstrap'],\n#     random_state=42,\n#     n_jobs=4\n# )\n\n# # Store Out-of-Fold (OOF) predictions\n# oof_preds = np.zeros(len(X))  # Initialize array for OOF predictions\n\n# # DataFrame to store out-of-fold predictions\n# oof_df = pd.DataFrame(columns=['ID', 'Actual', 'OOF_Pred_RF', 'Fold'])\n\n# # Cross-validation loop\n# for fold, (train_idx, val_idx) in enumerate(kf.split(X, y), start=1):\n#     print(f\"üîÑ Training Fold {fold}/{n_folds}...\")\n\n#     # Split into training and validation sets\n#     X_tr, X_val = X.iloc[train_idx], X.iloc[val_idx]\n#     y_tr, y_val = y.iloc[train_idx], y.iloc[val_idx]\n\n#     # Train the model on this fold\n#     rf_model.fit(X_tr, y_tr)\n\n#     # Predict on validation set\n#     y_val_pred = rf_model.predict(X_val)\n#     oof_preds[val_idx] = y_val_pred  # Store OOF predictions\n\n#     # Compute RMSE for this fold\n#     fold_rmse = mean_squared_error(y_val, y_val_pred, squared=False)\n#     print(f\"‚úÖ Fold {fold} RMSE: {fold_rmse:.4f}\")\n\n#     # Store fold results in DataFrame\n#     fold_df = pd.DataFrame({\n#         'ID': X.index[val_idx],  # Assuming index represents unique IDs\n#         'Actual': y_val.values,\n#         'OOF_Pred_RF': y_val_pred,\n#         'Fold': fold\n#     })\n#     oof_df = pd.concat([oof_df, fold_df], ignore_index=True)\n\n# # Compute overall Out-of-Fold (OOF) RMSE\n# oof_rmse = mean_squared_error(y, oof_preds, squared=False)\n# print(f\"\\nüèÜ Overall OOF RMSE: {oof_rmse:.4f}\")\n\n# # Save Out-of-Fold predictions\n# oof_df.to_csv('oof_predictions_rf.csv', index=False)\n# print(\"üìÇ OOF predictions saved to 'oof_predictions_rf.csv'.\")\n\n# # Save the final trained Random Forest model\n# joblib.dump(rf_model, 'random_forest_model.pkl')\n# print(\"‚úÖ Final trained model saved as 'random_forest_model.pkl'.\")\n\n# # Display first few rows of OOF predictions\n# oof_df.reset_index(drop=True, inplace=True)\n# print(oof_df.head()) ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-22T16:05:15.633205Z","iopub.execute_input":"2025-02-22T16:05:15.633590Z","iopub.status.idle":"2025-02-22T16:05:15.639067Z","shell.execute_reply.started":"2025-02-22T16:05:15.633532Z","shell.execute_reply":"2025-02-22T16:05:15.637641Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"# Make predictions\ny_pred = rf_model.predict(X_val)\nrmse = np.sqrt(mean_squared_error(y_val, y_pred))\nprint(f\"Validation RMSE: {rmse:.4f}\")\n\n# Predict on test dataset\ntest_predictions = rf_model.predict(X_test)\n\n# Ensure no negative predictions\ntest_predictions = np.maximum(test_predictions, 0)\n\n# Create submission file\nsubmission = pd.DataFrame({\"id\": test[\"id\"], \"Price\": test_predictions})\nsubmission.to_csv(\"submission_random_forest1.csv\", index=False)\n\nprint(\"Improved submission file saved as 'submission_random_forest.csv'\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-22T16:05:15.640310Z","iopub.execute_input":"2025-02-22T16:05:15.640753Z","iopub.status.idle":"2025-02-22T16:05:15.832368Z","shell.execute_reply.started":"2025-02-22T16:05:15.640713Z","shell.execute_reply":"2025-02-22T16:05:15.830847Z"}},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-9-5cb2ac061b0a>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Make predictions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrf_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mrmse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmean_squared_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Validation RMSE: {rmse:.4f}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'rf_model' is not defined"],"ename":"NameError","evalue":"name 'rf_model' is not defined","output_type":"error"}],"execution_count":9},{"cell_type":"code","source":"# import optuna\n# from sklearn.ensemble import RandomForestRegressor\n# from sklearn.model_selection import KFold, cross_val_score\n# from sklearn.metrics import mean_squared_error\n# import numpy as np\n\n# # Define the objective function for Optuna\n# def objective(trial):\n#     # Define the hyperparameter space to optimize\n#     params = {\n#         'n_estimators': trial.suggest_int('n_estimators', 100, 500, step=100),  # Number of trees\n#         'max_depth': trial.suggest_int('max_depth', 3, 20),  # Maximum depth of trees\n#         'min_samples_split': trial.suggest_int('min_samples_split', 2, 20),  # Minimum samples to split\n#         'min_samples_leaf': trial.suggest_int('min_samples_leaf', 1, 10),  # Minimum samples per leaf\n#         'max_features': trial.suggest_categorical('max_features', ['sqrt', 'log2', None]),  # Feature selection\n#         'bootstrap': trial.suggest_categorical('bootstrap', [True, False]),  # Whether to use bootstrapping\n#     }\n\n#     # Number of folds for cross-validation\n#     n_folds = 3\n#     kf = KFold(n_splits=n_folds, shuffle=True, random_state=42)\n\n#     # Perform cross-validation\n#     rf_model = RandomForestRegressor(random_state=42, n_jobs=-1, **params)\n#     scores = cross_val_score(rf_model, X, y, cv=kf, scoring='neg_root_mean_squared_error', n_jobs=-1)\n\n#     # Optuna minimizes the objective function, so we return the negative RMSE\n#     return -np.mean(scores)\n\n# # Run Optuna optimization\n# study = optuna.create_study(direction='minimize')  # Minimizing RMSE\n# study.optimize(objective, n_trials=3, n_jobs=-1)  # Perform 50 trials\n\n# # Best hyperparameters\n# best_params = study.best_params\n# print(f\"\\nüèÜ Best Parameters Found: {best_params}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-22T16:05:15.833009Z","iopub.status.idle":"2025-02-22T16:05:15.833400Z","shell.execute_reply":"2025-02-22T16:05:15.833258Z"}},"outputs":[],"execution_count":null}]}